{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (Any, Callable, Dict, Generic, Iterable, List, Mapping,\n",
    "                    NewType, Sequence, Tuple, TypeVar, Union)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "import math\n",
    "\n",
    "from operator import itemgetter\n",
    "from subprocess import PIPE, Popen, call\n",
    "import importlib\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import numpy as np  # type: ignore\n",
    "import pandas as pd  # type: ignore\n",
    "\n",
    "import fiona  # type: ignore\n",
    "from fiona.crs import from_epsg # type: ignore\n",
    "import geopandas as gpd  # type: ignore\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "import seaborn as sns  # type: ignore\n",
    "\n",
    "from arpeggio import ParserPython, visit_parse_tree  # type: ignore\n",
    "\n",
    "from arpeggio import RegExMatch, Optional, ZeroOrMore, OneOrMore, EOF, UnorderedGroup, And, Not, Combine  # type: ignore\n",
    "from arpeggio import ParserPython, PTNodeVisitor, visit_parse_tree, NoMatch  # type: ignore\n",
    "\n",
    "import soil_lib\n",
    "\n",
    "from soil_lib.LoimisLookups import siffer_rules_lookup, updated_texture_error_lookup\n",
    "\n",
    "from soil_lib.LoimisGrammarV2 import update_main_siffer_l, loimisp_short, loimisp_short_dk, parse_test, split_and_cut, consolidate_loimis, test_brackets, parse_reconstituate, load_default_texture_defensively, soilParts, soilParts_dk\n",
    "\n",
    "from soil_lib.LoimisVisitor import LpVisitor, loimis_grammar_product, test_layer_depths, set_texture_values\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# create logger\n",
    "#################\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# logfile = logging.FileHandler('temp_out/soil_convert.log', \"w\", encoding = \"utf-8\")\n",
    "console = logging.StreamHandler(sys.stdout)\n",
    "\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s [%(filename)s:%(lineno)d] - %(message)s')\n",
    "# logfile.setFormatter(formatter)\n",
    "console.setFormatter(formatter)\n",
    "\n",
    "# add the handlers to the logger\n",
    "logger.handlers = []\n",
    "# logger.addHandler(logfile)\n",
    "logger.addHandler(console)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #############################\n",
    "# global vars and path names\n",
    "##############################\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (25, 10)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "soil_legend_file = \"data/soil_types_legend.csv\"\n",
    "\n",
    "logger.info('##############################')\n",
    "logger.info(f'# loading soil legend, estonian and english descriptions: ({soil_legend_file})')\n",
    "logger.info('##############################')\n",
    "\n",
    "soil_legend_df = pd.read_csv(soil_legend_file, encoding='latin1', sep=';', quotechar='\"')\n",
    "soil_legend_lookup = soil_legend_df['T채histus kaardil'].tolist()\n",
    "soil_legend = set(soil_legend_lookup)\n",
    "\n",
    "logger.debug(soil_legend_df.sample(10))\n",
    "\n",
    "the_soilmap_dataset = 'data/Mullakaart.shp'\n",
    "\n",
    "soil_legend_df.sample(10)\n",
    "\n",
    "################\n",
    "\n",
    "siffer_update_matchinfo = 'data/soil_orig_siffer_update_matchinfo.csv'\n",
    "\n",
    "unique_loimis_list = 'data/unique_loimis1.csv'\n",
    "unique_loimis_with_siffer = 'data/unique_loimis1_with_siffer.csv'\n",
    "\n",
    "loimis_update_parseinfo = 'data/soil_orig_loimis_update_parseinfo.csv'\n",
    "\n",
    "shape_export_texture_values = 'data/eesti_soil_red1_texture_overview.shp'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the original sourcefile, or a progress checkpoint or export\n",
    "\n",
    "### soilmap shapefile from landboard\n",
    "\n",
    "https://geoportaal.maaamet.ee/docs/muld/Mullakaart_SHP.zip?t=20170301161200\n",
    "\n",
    "```\n",
    "#> md5sum Mullakaart_SHP.zip\n",
    "e6f25e2bd089926933df673798c9ac71 *Mullakaart_SHP.zip\n",
    "```\n",
    "\n",
    "### or from DataDOI deposit archive\n",
    "\n",
    "With English information\n",
    "\n",
    "https://datadoi.ut.ee/handle/33/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-cleanup\n",
    "start = datetime.datetime.now() # strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "logger.info('initialising and loading soil map: {}'.format(start))\n",
    "\n",
    "initial_soil_dataframe = gpd.read_file(the_soilmap_dataset, encoding='utf-8')\n",
    "\n",
    "initial_soil_dataframe['orig_fid'] = initial_soil_dataframe.index.copy()\n",
    "\n",
    "logger.debug(initial_soil_dataframe.sample(10))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far: {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger.info(\"#########################################\")\n",
    "logger.info(\"# apply dataframe update soil type code (siffer)\")\n",
    "logger.info(\"#########################################\")\n",
    "\n",
    "initial_soil_dataframe[['upd_siffer', 'siffer_upd_info']] = initial_soil_dataframe['Siffer'].apply(lambda x: update_main_siffer_l(x, soil_legend_lookup ))\n",
    "\n",
    "initial_soil_dataframe[['upd_sif1', 'sif1_upd_info']] = initial_soil_dataframe['Sif1'].astype(object).fillna(\"\").apply(lambda x: update_main_siffer_l(x, soil_legend_lookup ))\n",
    "\n",
    "initial_soil_dataframe[['upd_sif2', 'sif2_upd_info']] = initial_soil_dataframe['Sif2'].astype(object).fillna(\"\").apply(lambda x: update_main_siffer_l(x, soil_legend_lookup ))\n",
    "\n",
    "initial_soil_dataframe[['upd_sif3', 'sif3_upd_info']] = initial_soil_dataframe['Sif3'].astype(object).fillna(\"\").apply(lambda x: update_main_siffer_l(x, soil_legend_lookup ))\n",
    "\n",
    "initial_soil_dataframe[['upd_sif4', 'sif4_upd_info']] = initial_soil_dataframe['Sif4'].astype(object).fillna(\"\").apply(lambda x: update_main_siffer_l(x, soil_legend_lookup ))\n",
    "\n",
    "logger.debug(initial_soil_dataframe.sample(10))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far: {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"#########################################\")\n",
    "logger.info(\"# merge for soil types and WRB codes\")\n",
    "logger.info(\"#########################################\")\n",
    "\n",
    "initial_soil_dataframe = pd.merge(initial_soil_dataframe, soil_legend_df, left_on='upd_siffer', right_on='T채histus kaardil')\n",
    "initial_soil_dataframe.drop(['T채histus kaardil','nimetus','scientific_english'], axis=1, inplace=True)\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far: {}'.format(int(delta.total_seconds())))\n",
    "\n",
    "csv_drop1 = initial_soil_dataframe[\n",
    "    [ 'orig_fid', 'Siffer', 'upd_siffer', 'siffer_upd_info', 'WRB_code', 'Varv',\n",
    "      'Sif1', 'Osa1', 'upd_sif1', 'sif1_upd_info',\n",
    "      'Sif2', 'Osa2', 'upd_sif2', 'sif2_upd_info',\n",
    "      'Sif3', 'Osa3', 'upd_sif3', 'sif3_upd_info',\n",
    "      'Sif4', 'Osa4', 'upd_sif4', 'sif4_upd_info']]\n",
    "\n",
    "csv_drop1.to_csv(siffer_update_matchinfo, encoding=\"utf-8\")\n",
    "del(csv_drop1)\n",
    "\n",
    "initial_soil_dataframe.drop(['siffer_upd_info', \n",
    "      'Sif1', 'Osa1', 'upd_sif1', 'sif1_upd_info',\n",
    "      'Sif2', 'Osa2', 'upd_sif2', 'sif2_upd_info',\n",
    "      'Sif3', 'Osa3', 'upd_sif3', 'sif3_upd_info',\n",
    "      'Sif4', 'Osa4', 'upd_sif4', 'sif4_upd_info'], axis=1, inplace=True)\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far: {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"#########################################\")\n",
    "logger.info(\"# step by step loimis wrangling\")\n",
    "logger.info(\"#########################################\")\n",
    "\n",
    "# TODO\n",
    "t_parser = ParserPython(loimisp_short , memoization=False)\n",
    "tk_parser = ParserPython(loimisp_short_dk , memoization=False)\n",
    "\n",
    "unique_loimis1 = pd.Series(initial_soil_dataframe['Loimis1'].unique()).sort_values(ascending=True).reset_index(drop=True)\n",
    "unique_loimis1.to_csv(unique_loimis_list, encoding='utf-8')\n",
    "\n",
    "pf_df = pd.DataFrame(initial_soil_dataframe.groupby('Loimis1')['upd_siffer'].unique().reset_index())\n",
    "pf_df.to_csv(unique_loimis_with_siffer, encoding='utf-8')\n",
    "\n",
    "initial_soil_dataframe['split_layered'] = initial_soil_dataframe['Loimis1'].astype(object).fillna(\"no_info\").apply(lambda x: split_and_cut(x))\n",
    "initial_soil_dataframe['num_brackets_fixed'] = initial_soil_dataframe['split_layered'].apply(lambda x: test_brackets(x))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far: {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_soil_dataframe[['test_parse','test_parse_errors']] = initial_soil_dataframe['num_brackets_fixed'].apply(lambda x: parse_test(x, t_parser, tk_parser))\n",
    "\n",
    "logger.debug(initial_soil_dataframe.sample(10))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after parse_test): {}'.format(int(delta.total_seconds())))\n",
    "\n",
    "initial_soil_dataframe[['loimis_reconst','has_no_info']] = initial_soil_dataframe['test_parse'].apply(lambda x: parse_reconstituate(x))\n",
    "\n",
    "logger.debug(initial_soil_dataframe.loc[initial_soil_dataframe['has_no_info'] > 0].count())\n",
    "logger.debug(initial_soil_dataframe.loc[initial_soil_dataframe['has_no_info'] > 0].sample(10))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after parse_reconstituate): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_drop2 = initial_soil_dataframe[\n",
    "    [ 'orig_fid', 'Loimis1', 'Loimis2', 'Lihtloimis', 'Varv',\n",
    "      'split_layered', 'num_brackets_fixed',\n",
    "      'test_parse','test_parse_errors',\n",
    "      'loimis_reconst','has_no_info']]\n",
    "\n",
    "csv_drop2.to_csv(loimis_update_parseinfo, encoding=\"utf-8\")\n",
    "del(csv_drop2)\n",
    "\n",
    "initial_soil_dataframe.drop(['Loimis2',\n",
    "      'split_layered', 'num_brackets_fixed',\n",
    "      'test_parse','test_parse_errors'], axis=1, inplace=True)\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after parquet_checkpoint_loimis_fix): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"#########################################\")\n",
    "logger.info(\"# loimis grammar analysis\")\n",
    "logger.info(\"#########################################\")\n",
    "\n",
    "# drop v채rvs 0, 21, 22 (ocean/sea, under water (e.g. Peipsi), outside of EE territory))\n",
    "eesti_soil_red1 = initial_soil_dataframe.loc[initial_soil_dataframe['Varv'].isin(\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])].copy()\n",
    "\n",
    "del (initial_soil_dataframe)\n",
    "\n",
    "eesti_soil_red1[['loimis_reconst', 'has_no_info']] = eesti_soil_red1.apply(load_default_texture_defensively, axis=1)\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after load_default_texture_defensively): {}'.format(int(delta.total_seconds())))\n",
    "\n",
    "reorder = ['orig_fid', 'upd_siffer', 'WRB_code', 'Siffer', 'loimis_reconst', 'has_no_info', 'Loimis1', 'Lihtloimis', 'Huumus', 'Kivisus', 'Varv', 'Boniteet', 'Shape_Area', 'wkb_geom','geometry' ]\n",
    "eesti_soil_red1 = eesti_soil_red1[reorder]\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after df re-org): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_parser = ParserPython(soilParts , memoization=False)\n",
    "sp_tk_parser = ParserPython(soilParts_dk , memoization=False)\n",
    "\n",
    "eesti_soil_red1[['loimis_grammar','parse_info']] = eesti_soil_red1['loimis_reconst'].apply(lambda x: loimis_grammar_product(x, sp_tk_parser))\n",
    "\n",
    "loimis_stats(eesti_soil_red1, 'parse_info')\n",
    "eesti_soil_red1[['Loimis1', 'loimis_reconst', 'has_no_info', 'loimis_grammar','parse_info']].sample(15)\n",
    "\n",
    "\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['parse_info'].isin(['empty_loimis'])].index.size)\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after loimis_grammar_product): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"#########################################\")\n",
    "logger.info(\"# loimis grammar analysis layer values\")\n",
    "logger.info(\"#########################################\")\n",
    "\n",
    "eesti_soil_red1[['nlayers', 'SOL_ZMX', 'SOL_Z1', 'SOL_Z2', 'SOL_Z3', 'SOL_Z4']] = eesti_soil_red1['loimis_grammar'].apply(lambda x: test_layer_depths(x))\n",
    "\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['SOL_ZMX'] < 100].sample(15))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after test_layer_depths): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"#########################################\")\n",
    "logger.info(\"# apply dataframe set_texture_values \")\n",
    "logger.info(\"#########################################\")\n",
    "\n",
    "eesti_soil_red1[['EST_TXT1', 'LXTYPE1', 'SOL_CLAY1', 'SOL_SILT1', 'SOL_SAND1', 'SOL_ROCK1',\n",
    "                 'EST_TXT2', 'LXTYPE2', 'SOL_CLAY2', 'SOL_SILT2', 'SOL_SAND2', 'SOL_ROCK2',\n",
    "                 'EST_TXT3', 'LXTYPE3', 'SOL_CLAY3', 'SOL_SILT3', 'SOL_SAND3', 'SOL_ROCK3',\n",
    "                 'EST_TXT4', 'LXTYPE4', 'SOL_CLAY4', 'SOL_SILT4', 'SOL_SAND4', 'SOL_ROCK4']] = eesti_soil_red1['loimis_grammar'].apply(lambda x: set_texture_values(x))\n",
    "\n",
    "logger.info(eesti_soil_red1.sample(10))\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after set_texture_values): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['SOL_ROCK1'] > 20].count())\n",
    "\n",
    "logger.info(set(eesti_soil_red1['LXTYPE1'].unique()))\n",
    "logger.info(set(eesti_soil_red1['LXTYPE2'].unique()))\n",
    "logger.info(set(eesti_soil_red1['LXTYPE3'].unique()))\n",
    "logger.info(set(eesti_soil_red1['LXTYPE4'].unique()))\n",
    "\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE1'] == 0].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE1'].isin(['no_info'])].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE1'].isin([''])].index.size)\n",
    "\n",
    "\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE2'] == 0].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE2'].isin(['no_info'])].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE2'].isin([''])].index.size)\n",
    "\n",
    "\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE3'] == 0].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE3'].isin(['no_info'])].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE3'].isin([''])].index.size)\n",
    "\n",
    "\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE4'] == 0].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE4'].isin(['no_info'])].index.size)\n",
    "logger.info(eesti_soil_red1.loc[eesti_soil_red1['LXTYPE4'].isin([''])].index.size)\n",
    "\n",
    "# check pointing\n",
    "# 'orig_fid', 'upd_siffer', 'WRB_code', 'Siffer', 'loimis_reconst', 'has_no_info', 'Loimis1', 'Lihtloimis', 'Huumus', 'Kivisus', 'Varv', 'Boniteet', 'Shape_Area', 'wkb_geom','geometry'\n",
    "csv_drop1 = eesti_soil_red1[['orig_fid','Loimis1','loimis_reconst','Lihtloimis','EST_TXT1', 'LXTYPE1','EST_TXT2', 'LXTYPE2','EST_TXT3', 'LXTYPE3','EST_TXT4', 'LXTYPE4']]\n",
    "csv_drop1.to_csv(soil_orig_texture_parse, encoding=\"utf-8\")\n",
    "del(csv_drop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_texture_df = eesti_soil_red1[['orig_fid', 'upd_siffer', 'WRB_code',\n",
    "    'Boniteet', 'Varv', 'Loimis1', 'loimis_reconst',\n",
    "    'nlayers', 'SOL_ZMX', 'SOL_Z1', 'SOL_Z2', 'SOL_Z3', 'SOL_Z4',\n",
    "    'EST_TXT1', 'LXTYPE1',\n",
    "    'EST_TXT2', 'LXTYPE2',\n",
    "    'EST_TXT3', 'LXTYPE3',\n",
    "    'EST_TXT4', 'LXTYPE4',\n",
    "    'SOL_CLAY1', 'SOL_SILT1', 'SOL_SAND1', 'SOL_ROCK1',\n",
    "    'SOL_CLAY2', 'SOL_SILT2', 'SOL_SAND2', 'SOL_ROCK2',\n",
    "    'SOL_CLAY3', 'SOL_SILT3', 'SOL_SAND3', 'SOL_ROCK3',\n",
    "    'SOL_CLAY4', 'SOL_SILT4', 'SOL_SAND4', 'SOL_ROCK4', 'geometry']]\n",
    "\n",
    "tmp_texture_df.to_file(driver='ESRI Shapefile', filename=shape_export_texture_values, encoding=\"utf-8\")\n",
    "del(tmp_texture_df)\n",
    "\n",
    "# sys.exit(0)\n",
    "\n",
    "tmp_step = datetime.datetime.now()\n",
    "delta = tmp_step - start\n",
    "logger.info('elapsed seconds so far (after checkpointing and textures physical): {}'.format(int(delta.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Geo",
   "language": "python",
   "name": "geopython-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
